{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "#from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.densenet import DenseNet121,DenseNet169\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imgaug as ia\n",
    "\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 300\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/aptos2019-blindness-detection/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0011ace640cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/aptos2019-blindness-detection/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/aptos2019-blindness-detection/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \"\"\"\n\u001b[1;32m-> 1357\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    640\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/aptos2019-blindness-detection/train.csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "df_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising some sample pictures of different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cde957d9812c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdisplay_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "def display_samples(df, columns=4, rows=3):\n",
    "    fig=plt.figure(figsize=(5*columns, 4*rows))\n",
    "\n",
    "    for i in range(columns*rows):\n",
    "        image_path = df.loc[i,'id_code']\n",
    "        image_id = df.loc[i,'diagnosis']\n",
    "        img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.title(image_id)\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "display_samples(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fba80e09128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df_train['id_code']\n",
    "y = df_train['diagnosis']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)\n",
    "y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-eaf4a8f1328d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n\u001b[0;32m      3\u001b[0m                                                       stratify=y, random_state=8)\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n",
    "                                                      stratify=y, random_state=8)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
    "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                [\n",
    "                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                    iaa.OneOf([\n",
    "                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
    "                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
    "                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                    # search either for all edges or for directed edges,\n",
    "                    # blend the result with the original image using a blobby mask\n",
    "                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                    ])),\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
    "                    ]),\n",
    "                    iaa.Invert(0.01, per_channel=True), # invert color channels\n",
    "                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
    "                    # either change the brightness of the whole image (sometimes\n",
    "                    # per channel) or change the brightness of subareas\n",
    "                    iaa.OneOf([\n",
    "                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                        iaa.FrequencyNoiseAlpha(\n",
    "                            exponent=(-1, 0),\n",
    "                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                            second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                        )\n",
    "                    ]),\n",
    "                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                ],\n",
    "                random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels,\n",
    "                 batch_size, is_train=True,\n",
    "                 mix=False, augment=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.is_augment = augment\n",
    "        if(self.is_train):\n",
    "            self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('../input/aptos2019-blindness-detection/train_images/'+sample+'.png')\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            if(self.is_augment):\n",
    "                img = seq.augment_image(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('../input/aptos2019-blindness-detection/train_images/'+sample+'.png')\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = DenseNet121(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights(\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\")\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "epochs = 30; batch_size = 32\n",
    "checkpoint = ModelCheckpoint('../working/densenet_.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=9)\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
    "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
    "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
    "\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference link: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow\n",
    "def kappa_loss(y_true, y_pred, y_pow=2, eps=1e-12, N=5, bsize=32, name='kappa'):\n",
    "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
    "        Args:\n",
    "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
    "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
    "            y_pow: int,  e.g. y_pow=2\n",
    "            N: typically num_classes of the model\n",
    "            bsize: batch_size of the training or validation ops\n",
    "            eps: a float, prevents divide by zero\n",
    "            name: Optional scope/name for op_scope.\n",
    "        Returns:\n",
    "            A tensor with the kappa loss.\"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        y_true = tf.to_float(y_true)\n",
    "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
    "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
    "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
    "    \n",
    "        pred_ = y_pred ** y_pow\n",
    "        try:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
    "        except Exception:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
    "    \n",
    "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
    "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
    "    \n",
    "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
    "    \n",
    "        nom = tf.reduce_sum(weights * conf_mat)\n",
    "        denom = tf.reduce_sum(weights * tf.matmul(\n",
    "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
    "                              tf.to_float(bsize))\n",
    "    \n",
    "        return nom*0.5 / (denom + eps) + categorical_crossentropy(y_true, y_pred)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class QWKEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), batch_size=64, interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_generator, self.y_val = validation_data\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_generator(generator=self.valid_generator,\n",
    "                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n",
    "                                                  workers=1, use_multiprocessing=False,\n",
    "                                                  verbose=1)\n",
    "            def flatten(y):\n",
    "                return np.argmax(y, axis=1).reshape(-1)\n",
    "            \n",
    "            score = cohen_kappa_score(flatten(self.y_val),\n",
    "                                      flatten(y_pred),\n",
    "                                      labels=[0,1,2,3,4],\n",
    "                                      weights='quadratic')\n",
    "            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n",
    "            self.history.append(score)\n",
    "            if score >= max(self.history):\n",
    "                print('saving checkpoint: ', score)\n",
    "                self.model.save('../working/densenet_bestqwk.h5')\n",
    "\n",
    "qwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n",
    "                    batch_size=batch_size, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25/25 [==============================] - 169s 7s/step - loss: 1.4869\n",
      "18/18 [==============================] - 87s 5s/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.019317 \n",
      "\n",
      "saving checkpoint:  0.019316860824614923\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 93s 4s/step - loss: 0.8496\n",
      "18/18 [==============================] - 83s 5s/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.086986 \n",
      "\n",
      "saving checkpoint:  0.08698580446274606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb61daec240>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-3,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
    "    epochs=2,\n",
    "    workers=WORKERS, use_multiprocessing=True,\n",
    "    verbose=1,\n",
    "    callbacks=[qwk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "98/98 [==============================] - 337s 3s/step - loss: 0.8684 - val_loss: 0.5605\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56055, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 1 - QWK_score: 0.832198 \n",
      "\n",
      "saving checkpoint:  0.8321981079307581\n",
      "Epoch 2/30\n",
      "98/98 [==============================] - 277s 3s/step - loss: 0.7188 - val_loss: 0.5115\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56055 to 0.51151, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 2 - QWK_score: 0.879797 \n",
      "\n",
      "saving checkpoint:  0.879796813566955\n",
      "Epoch 3/30\n",
      "98/98 [==============================] - 279s 3s/step - loss: 0.6681 - val_loss: 0.5451\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51151\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 3 - QWK_score: 0.877107 \n",
      "\n",
      "Epoch 4/30\n",
      "98/98 [==============================] - 281s 3s/step - loss: 0.6207 - val_loss: 0.5195\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51151\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 4 - QWK_score: 0.858153 \n",
      "\n",
      "Epoch 5/30\n",
      "98/98 [==============================] - 278s 3s/step - loss: 0.5866 - val_loss: 0.4934\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.51151 to 0.49342, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 5 - QWK_score: 0.878248 \n",
      "\n",
      "Epoch 6/30\n",
      "98/98 [==============================] - 282s 3s/step - loss: 0.5475 - val_loss: 0.4865\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49342 to 0.48647, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 6 - QWK_score: 0.879557 \n",
      "\n",
      "Epoch 7/30\n",
      "98/98 [==============================] - 283s 3s/step - loss: 0.5721 - val_loss: 0.4827\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48647 to 0.48271, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 7 - QWK_score: 0.862395 \n",
      "\n",
      "Epoch 8/30\n",
      "98/98 [==============================] - 282s 3s/step - loss: 0.5341 - val_loss: 0.4831\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48271\n",
      "18/18 [==============================] - 63s 3s/step\n",
      "\n",
      " epoch: 8 - QWK_score: 0.900837 \n",
      "\n",
      "saving checkpoint:  0.9008374417925109\n",
      "Epoch 9/30\n",
      "98/98 [==============================] - 277s 3s/step - loss: 0.5169 - val_loss: 0.4463\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.48271 to 0.44631, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 9 - QWK_score: 0.891050 \n",
      "\n",
      "Epoch 10/30\n",
      "98/98 [==============================] - 280s 3s/step - loss: 0.5279 - val_loss: 0.5110\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44631\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 10 - QWK_score: 0.868824 \n",
      "\n",
      "Epoch 11/30\n",
      "98/98 [==============================] - 281s 3s/step - loss: 0.5173 - val_loss: 0.4298\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44631 to 0.42978, saving model to ../working/densenet_.h5\n",
      "18/18 [==============================] - 60s 3s/step\n",
      "\n",
      " epoch: 11 - QWK_score: 0.903489 \n",
      "\n",
      "saving checkpoint:  0.9034893910064694\n",
      "Epoch 12/30\n",
      "98/98 [==============================] - 280s 3s/step - loss: 0.4816 - val_loss: 0.4469\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 12 - QWK_score: 0.908825 \n",
      "\n",
      "saving checkpoint:  0.908824827522126\n",
      "Epoch 13/30\n",
      "98/98 [==============================] - 278s 3s/step - loss: 0.4806 - val_loss: 0.4602\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 13 - QWK_score: 0.898599 \n",
      "\n",
      "Epoch 14/30\n",
      "98/98 [==============================] - 278s 3s/step - loss: 0.4676 - val_loss: 0.4503\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 14 - QWK_score: 0.903152 \n",
      "\n",
      "Epoch 15/30\n",
      "98/98 [==============================] - 278s 3s/step - loss: 0.4572 - val_loss: 0.4737\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.42978\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "18/18 [==============================] - 60s 3s/step\n",
      "\n",
      " epoch: 15 - QWK_score: 0.892415 \n",
      "\n",
      "Epoch 16/30\n",
      "98/98 [==============================] - 278s 3s/step - loss: 0.4297 - val_loss: 0.4449\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 16 - QWK_score: 0.902185 \n",
      "\n",
      "Epoch 17/30\n",
      "98/98 [==============================] - 275s 3s/step - loss: 0.4089 - val_loss: 0.4539\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 17 - QWK_score: 0.903247 \n",
      "\n",
      "Epoch 18/30\n",
      "98/98 [==============================] - 279s 3s/step - loss: 0.4086 - val_loss: 0.4560\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 18 - QWK_score: 0.903975 \n",
      "\n",
      "Epoch 19/30\n",
      "98/98 [==============================] - 281s 3s/step - loss: 0.4129 - val_loss: 0.4460\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.42978\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "18/18 [==============================] - 62s 3s/step\n",
      "\n",
      " epoch: 19 - QWK_score: 0.906624 \n",
      "\n",
      "Epoch 20/30\n",
      "98/98 [==============================] - 281s 3s/step - loss: 0.3765 - val_loss: 0.4343\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.42978\n",
      "18/18 [==============================] - 61s 3s/step\n",
      "\n",
      " epoch: 20 - QWK_score: 0.905998 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba80e41438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            # loss=kappa_loss,\n",
    "            optimizer=Adam(lr=1e-4))\n",
    "model.fit_generator(\n",
    "    train_mixup,\n",
    "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1, use_multiprocessing=False,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n",
    "model.load_weights('../working/densenet_bestqwk.h5')\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1928it [03:25,  9.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# reference:https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb \n",
    "for i, name in tqdm(enumerate(submit['id_code'])):\n",
    "    path = os.path.join('../input/aptos2019-blindness-detection/test_images/', name+'.png')\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (SIZE, SIZE))\n",
    "    X = np.array((image[np.newaxis])/255)\n",
    "    score_predict=((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n",
    "    label_predict = np.argmax(score_predict)\n",
    "    predicted.append(str(label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code diagnosis\n",
       "0  0005cfc8afb6         1\n",
       "1  003f0afdcd15         3\n",
       "2  006efc72b638         2\n",
       "3  00836aaacf06         2\n",
       "4  009245722fa4         2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['diagnosis'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
